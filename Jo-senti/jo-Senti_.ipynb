{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d402965",
   "metadata": {},
   "source": [
    "# 1. Setup and Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a02a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datasets import load_dataset\n",
    "\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9ba14",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ecbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"komari6/ajgt_twitter_ar\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df.rename(columns={'label': 'Sentiment', 'text': 'Text'}, inplace=True)\n",
    "\n",
    "stemmer = ISRIStemmer()\n",
    "arabic_stopwords = set(stopwords.words('arabic'))\n",
    "custom_stops = {'Ø§Ù†Ø§', 'Ø§Ù†Øª', 'Ø§Ø­Ù†Ø§', 'Ù‡Ù…', 'Ù„Ù‡Ù…', 'Ù„Ù†Ø§', 'ÙÙŠ', 'Ù…Ù†', 'Ø¹Ù„Ù‰', 'Ø¹Ù†', 'Ù…Ø¹', 'Ø§Ù„Ù„ÙŠ', 'Ø´Ùˆ', 'ÙˆÙŠÙ†', 'ÙƒÙŠÙ', 'Ù…Ø§', 'ÙŠØ§', 'Ø¨Ù†Ø§', 'Ø§Ù„Ù„Ù‡Ù…'}\n",
    "arabic_stopwords.update(custom_stops)\n",
    "\n",
    "def clean_and_process(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[ÙÙ‹ÙÙŒÙÙÙ’Ù‘]', '', text)\n",
    "    text = re.sub(r'[Ø£Ø¥Ø¢]', 'Ø§', text)\n",
    "    text = re.sub(r'Ø©', 'Ù‡', text)\n",
    "    text = re.sub(r'Ù‰', 'ÙŠ', text)\n",
    "    text = re.sub(r'[^\\u0600-\\u06ff\\s]', '', text)\n",
    "    \n",
    "    words = text.split()\n",
    "    processed_words = [stemmer.stem(w) for w in words if w not in arabic_stopwords]\n",
    "    return \" \".join(processed_words)\n",
    "\n",
    "df['Clean_Text'] = df['Text'].apply(clean_and_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b781d",
   "metadata": {},
   "source": [
    "# 3. Model Training (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f30452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 86.39%\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=4000)\n",
    "X = tfidf.fit_transform(df['Clean_Text']).toarray()\n",
    "y = df['Sentiment'].apply(lambda x: 1 if str(x) in ['1', 'Positive'] else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "model = LogisticRegression(C=10, solver='liblinear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy_score(y_test, model.predict(X_test)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b325c2f",
   "metadata": {},
   "source": [
    "# 4. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032d2aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Words:\n",
      "['Ø§Ù„Ù„' 'Ø±Ø²Ù‚' 'ÙŠØ±Ø¨' 'Ø±Ø¨Ù†' 'Ø¬Ø¹Ù„' 'Ø³Ù„Ù…' 'Ø®ÙŠØ±' 'Ø±Ø¦Ø¹' 'ØµÙ„Ø­' 'Ø¬Ù…Ù„']\n",
      "\n",
      "Top Negative Words:\n",
      "['Ø´Ø¹Ø¨' 'Ù‚Ø±Ù' 'Ø³Ø®Ù' 'Ù…Ø´' 'Ø³Ø®Ø±' 'Ø¬Ù…Ù„ Ù„Ø­Ø¨' 'Ù†ÙˆÙŠ' 'ÙƒÙ„Ø¨' 'Ø§Ø®Ùˆ' 'ÙˆØ·Ù†']\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "coefs = model.coef_[0]\n",
    "feature_importance = pd.DataFrame({'Word': feature_names, 'Weight': coefs})\n",
    "\n",
    "print(\"Top Positive Words:\")\n",
    "print(feature_importance.sort_values(by='Weight', ascending=False).head(10)['Word'].values)\n",
    "\n",
    "print(\"\\nTop Negative Words:\")\n",
    "print(feature_importance.sort_values(by='Weight', ascending=True).head(10)['Word'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565c1a2",
   "metadata": {},
   "source": [
    "# 5. Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0341251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, 'jo_senti_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "print(\"Model and Vectorizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969d26b",
   "metadata": {},
   "source": [
    "# 6. Interactive Application (Hybrid System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4821c75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ee87d2dbf0490d994f586f8076e49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h2 style='color:#2c3e50'>Jo-Senti: Smart Hybrid App</h2>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7594aa7cd1f46518e6206771b56d5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='100px', width='80%'), placeholder='Type here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c13cd0f2cb4c5f96cf1e00a514d8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Analyze', icon='rocket', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6c3eda96ae4b90bf9f036048b2cf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model = joblib.load('jo_senti_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "pos_keywords = {'ÙƒÙÙˆ', 'Ù†Ø´Ù…ÙŠ', 'ÙˆØ­Ø´', 'Ù‚Ø¯Ù‡Ø§', 'Ø¨Ø´Ù‡ÙŠ', 'Ø¨Ø¬Ù†Ù†', 'Ø®Ø±Ø§ÙÙŠ', 'ÙØ®Ù…', 'Ø±Ø§Ø¦Ø¹', 'Ø²Ø§ÙƒÙŠ', 'Ø¹ÙÙŠØ©', 'Ù…Ø¹Ù„Ù…', 'Ø´ÙŠØ®', 'Ù…Ø´ Ø¨Ø·Ø§Ù„', 'ÙŠØ¹Ø·ÙŠÙƒ Ø§Ù„Ø¹Ø§ÙÙŠØ©', 'Ù…Ø§ Ù‚ØµØ±Øª'}\n",
    "neg_keywords = {'Ø²ÙØª', 'Ù‚Ø±Ù', 'Ø³ÙŠØ¡', 'Ø®Ø²ÙŠ', 'ÙØ§Ø´Ù„', 'Ø­Ù‚ÙŠØ±', 'ÙƒÙ„Ø¨', 'Ø³Ø®ÙŠÙ', 'Ù…Ø´ Ù†Ø§ÙØ¹', 'Ø¹Ø¯Ù… Ø§Ù„Ù…Ø¤Ø§Ø®Ø°Ø©'}\n",
    "\n",
    "header = widgets.HTML(\"<h2 style='color:#2c3e50'>Jo-Senti: Smart Hybrid App</h2>\")\n",
    "text_input = widgets.Textarea(placeholder='Type here...', layout=widgets.Layout(width='80%', height='100px'))\n",
    "button = widgets.Button(description='Analyze', button_style='primary', icon='rocket')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_analyze(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        sentence = text_input.value\n",
    "        if not sentence: return\n",
    "        \n",
    "        cleaned = clean_and_process(sentence)\n",
    "        input_words = sentence.split()\n",
    "        \n",
    "        def check_keyword(keywords, text, words_list):\n",
    "            for k in keywords:\n",
    "                if ' ' in k:\n",
    "                    if k in text: return True\n",
    "                else:\n",
    "                    if k in words_list: return True\n",
    "            return False\n",
    "\n",
    "        found_pos = check_keyword(pos_keywords, sentence, input_words)\n",
    "        found_neg = check_keyword(neg_keywords, sentence, input_words)\n",
    "        \n",
    "        vec = loaded_vectorizer.transform([cleaned]).toarray()\n",
    "        pred = loaded_model.predict(vec)[0]\n",
    "        prob = loaded_model.predict_proba(vec)[0].max()\n",
    "        \n",
    "        if found_pos:\n",
    "            res, color, src = \"Positive ğŸ˜\", \"#d4edda\", \"Golden Phrase\"\n",
    "        elif found_neg:\n",
    "            res, color, src = \"Negative ğŸ˜¡\", \"#f8d7da\", \"Blacklist Phrase\"\n",
    "        else:\n",
    "            if pred == 1:\n",
    "                res, color, src = f\"Positive ğŸ˜Š\", \"#e8f8f5\", f\"AI Model ({prob:.0%})\"\n",
    "            else:\n",
    "                res, color, src = f\"Negative ğŸ˜”\", \"#fcf3cf\", f\"AI Model ({prob:.0%})\"\n",
    "\n",
    "        display(widgets.HTML(f\"<div style='background-color:{color}; padding:15px; border-radius:10px;'><h3>Result: {res}</h3><p>Source: {src}</p></div>\"))\n",
    "\n",
    "button.on_click(on_analyze)\n",
    "display(header, text_input, button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
